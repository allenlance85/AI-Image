```
# Import required libraries
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate
from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from sklearn.utils import shuffle
from IPython.display import Image, display

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Set image size and latent dimension
img_rows = 64
img_cols = 64
channels = 3
img_shape = (img_rows, img_cols, channels)
z_dim = 100

# Define generator network
def build_generator(z_dim):
    model = Sequential()

    model.add(Dense(128 * 16 * 16, activation="relu", input_dim=z_dim))
    model.add(Reshape((16, 16, 128)))
    model.add(UpSampling2D())
  
    model.add(Conv2D(128, kernel_size=3, padding="same"))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Activation("relu"))
    model.add(UpSampling2D())

    model.add(Conv2D(64, kernel_size=3, padding="same"))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Activation("relu"))

    model.add(Conv2D(channels, kernel_size=3, padding="same"))
    model.add(Activation("tanh"))

    z = Input(shape=(z_dim,))
    img = model(z)

    return Model(z, img)

# Define discriminator network
def build_discriminator(img_shape):
    model = Sequential()

    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding="same"))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, kernel_size=3, strides=2, padding="same"))
    model.add(ZeroPadding2D(padding=((0,1),(0,1))))
    model.add(BatchNormalization(momentum=0.8))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))

    model.add(Conv2D(128, kernel_size=3, strides=2, padding="same"))
    model.add(BatchNormalization(momentum=0.8))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))

    model.add(Conv2D(256, kernel_size=3, strides=1, padding="same"))
    model.add(BatchNormalization(momentum=0.8))
    model.add(LeakyReLU(alpha=0.2))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))

    img = Input(shape=img_shape)
    z = Flatten()(img)
    z = Dense(512)(z)
    z = LeakyReLU(alpha=0.2)(z)
    z = Concatenate()([z, input_text])
    validity = model(z)

    return Model([img, input_text], validity)

# Define text encoder network
def build_text_encoder():
    model = Sequential()

    model.add(Dense(512, input_dim=text_dim))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Activation("relu"))

    model.add(Dense(256))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Activation("relu"))

    model.add(Dense(z_dim))
    model.add(BatchNormalization(momentum=0.8))
    model.add(Activation("tanh"))

    input_text = Input(shape=(text_dim,))
    z = model(input_text)

    return Model(input_text, z)

# Define combined generator and discriminator network
def build_gan(generator, discriminator):
    discriminator.trainable = False

    z = Input(shape=(z_dim,))
    text = Input(shape=(text_dim,))
    img = generator([z, text])
    validity = discriminator([img, text])

    return Model([z, text], validity)

# Load dataset
data_generator = ImageDataGenerator(rescale=1./255)
dataset = data_generator.flow_from_directory("path/to/female-fantasy-creatures-dataset", target_size=(img_rows, img_cols), batch_size=batch_size, class_mode=None)

# Build networks
text_encoder = build_text_encoder()
generator = build_generator(z_dim)
discriminator = build_discriminator(img_shape)

# Compile discriminator
optimizer = Adam(0.0002, 0.5)
discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Build GAN
gan = build_gan(generator, discriminator)
optimizer = Adam(0.0002, 0.5)
gan.compile(loss='binary_crossentropy', optimizer=optimizer)

# Training loop
epochs = 10000
batch_size = 32
sample_interval = 500

for epoch in range(epochs):
    # Select a random batch of images
    idx = np.random.randint(0, dataset.shape[0], batch_size)
    imgs = dataset[idx]

    # Generate noise and text vectors
    noise = np.random.normal(0, 1, (batch_size, z_dim))
    text = np.random.rand(batch_size, text_dim)

    # Generate a batch of fake images
    gen_imgs = generator.predict([noise, text])

    # Train discriminator
    d_loss_real = discriminator.train_on_batch([imgs, text], np.ones((batch_size, 1)))
    d_loss_fake = discriminator.train_on_batch([gen_imgs, text], np.zeros((batch_size, 1)))
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # Train generator
    g_loss = gan.train_on_batch([noise, text], np.ones((batch_size, 1)))

    # Print progress
    if epoch % sample_interval == 0:
        print(f"Epoch {epoch}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}")

        # Save generated images
        noise = np.random.normal(0, 1, (1, z_dim))
        text = np.random.rand(1, text_dim)
        gen_img = generator.predict([noise, text])[0]
        gen_img = array_to_img(gen_img)
        display(gen_img)
```
